{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study: MNIST hand-written digits dataset\n",
    "\n",
    "##### License: Apache 2.0\n",
    "\n",
    "\n",
    "This notebook shows how to use topological data analysis to generate features for classifying digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "The first step consists in importing relevant *gtda* components and other useful libraries or modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from gtda.images import Binarizer, Inverter, ImageToPointCloud, HeightFiltration, DilationFiltration, RadialFiltration, ErosionFiltration, SignedDistanceFiltration\n",
    "from pgtda.images import DensityFiltration\n",
    "from gtda.homology import VietorisRipsPersistence, CubicalPersistence\n",
    "from gtda.diagrams import ForgetDimension, PairwiseDistance, Amplitude, Scaler, PersistenceEntropy, BettiCurve, PersistenceLandscape, HeatKernel\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "from gtda.diagrams._utils import _subdiagrams\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(X):\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15,10))\n",
    "    axes = axes.flatten()\n",
    "    cmap = plt.cm.binary\n",
    "    cmap.set_bad('y')\n",
    "    vmin, vmax = np.min(X[X != np.inf]), np.max(X[X != np.inf])\n",
    "    \n",
    "    for i in range(20):\n",
    "        axes[i].imshow(X[i], cmap='binary', vmin=vmin, vmax=vmax)\n",
    "        axes[i].axis('off') # hide the axes ticks\n",
    "        axes[i].set_title('Correct label is '+str(int(y_train[i])), color= 'black', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_clouds(X):\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15,10))\n",
    "    axes = axes.flatten()\n",
    "    cmap = plt.cm.binary\n",
    "    cmap.set_bad('y')\n",
    "    vmin, vmax = np.min(X[X != np.inf]), np.max(X[X != np.inf])\n",
    "\n",
    "    for i in range(20):\n",
    "        axes[i].plot(X[i, :, 0], X[i, :, 1], marker='s', linestyle='')\n",
    "        axes[i].set_xlim(0, 27)\n",
    "        axes[i].set_ylim(0, 27)\n",
    "        axes[i].axis('off') # hide the axes ticks\n",
    "        axes[i].set_title('Correct label is '+str(int(y_train[i])), color= 'black', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagrams(X):\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15,10))\n",
    "    axes = axes.flatten()\n",
    "    colors = {0: 'b', 1: 'r', 2: 'g'}\n",
    "    homology_dimensions = sorted(list(set(X[0, :, 2])))\n",
    "    \n",
    "    vmin, vmax = np.inf, -np.inf\n",
    "    for i in range(20):\n",
    "        for dim in homology_dimensions:\n",
    "            diagram_dim = _subdiagrams(X, [dim], remove_dim=True)[i]\n",
    "            vmin, vmax = min(vmin, np.min(diagram_dim)), max(vmax, np.max(diagram_dim))\n",
    "            axes[i].plot(diagram_dim[:,0], diagram_dim[:,1], 'o', color=colors[int(dim)])\n",
    "            \n",
    "    for i in range(20):\n",
    "        axes[i].plot([vmin, vmax], [vmin, vmax], color='k')\n",
    "        axes[i].set_title('Diagram for label '+str(int(y_train[i])), color= 'black', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(X):\n",
    "    figure = plt.figure(figsize=(15,10))\n",
    "    vmin, vmax = np.min(X), np.max(X)\n",
    "\n",
    "    plt.imshow(X)\n",
    "    figure.subplots_adjust(bottom=0.2)\n",
    "    cbar_ax = figure.add_axes([0.3, 0.2, 0.4, 0.03])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colorbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('Filtration values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrices(X):\n",
    "    n_matrices = 20\n",
    "    figure, axes = plt.subplots(4, 5, figsize=(15,10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    iterator = tuple(itertools.product(range(n_matrices), range(1)))\n",
    "    axes = axes.reshape((1, n_matrices))\n",
    "    vmin, vmax = np.min(X), np.max(X)\n",
    "    for i, j in iterator:\n",
    "        plot = axes[j, i].imshow(X[i], vmin=vmin, vmax=vmax)\n",
    "        axes[j, i].axis('off') # hide the axes ticks\n",
    "\n",
    "    figure.subplots_adjust(bottom=0.2)\n",
    "    cbar_ax = figure.add_axes([0.3, 0.2, 0.4, 0.03])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colorbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('Filtration values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(X, y=None, n_curves=1):\n",
    "    figure = plt.figure(figsize=(10,5))\n",
    "    n_points = X.shape[0] // n_curves\n",
    "    if y is None:\n",
    "        y = np.arange(n_points)\n",
    "    for i in range(n_curves):\n",
    "        X_curve = X[i*n_points:(i+1)*n_points]\n",
    "        plt.plot(y, X_curve)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data here: https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz\n",
    "((X, y), (X_valid, y_valid), _) = pkl.load(gzip.open('/home/rookstar/Downloads/mnist.pkl.gz', 'rb'), encoding='latin-1')\n",
    "\n",
    "X = X.reshape((-1, 28, 28))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "\n",
    "n_train, n_test = 40000, 10000\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:n_train+n_test]\n",
    "y_test = y[n_train:n_train+n_test]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples of the input data\n",
    "We choose the first 20 samples from the training set and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=0.4)\n",
    "binarizer.fit(X_train[:20])\n",
    "X_train_binarized = binarizer.transform(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming an image to a point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_transformer = ImageToPointCloud()\n",
    "point_cloud_transformer.fit(X_train[:20])\n",
    "X_train_points = point_cloud_transformer.transform(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_point_clouds(X_train_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rips_complex = VietorisRipsPersistence(metric='euclidean', max_edge_length=100, \n",
    "                                       homology_dimensions=(0, 1))\n",
    "rips_complex.fit(X_train_points)\n",
    "X_train_rips = rips_complex.transform(X_train_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagrams(X_train_rips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the persistence landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape = PersistenceLandscape(n_bins=1000, n_layers=3, n_jobs=1)\n",
    "landscape.fit(X_train_rips)\n",
    "X_train_landscape = landscape.transform(X_train_rips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_landscape.shape)\n",
    "plot_curve(X_train_landscape[1,1,0,:], landscape.samplings_[1.0].reshape(-1,), n_curves=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the heat kernel of stacked diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_stacker = ForgetDimension()\n",
    "diagram_stacker.fit(X_train_rips)\n",
    "X_train_stacked = diagram_stacker.transform(X_train_rips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betti = BettiCurve(n_bins=100, n_jobs=1)\n",
    "betti.fit(X_train_stacked)\n",
    "X_train_betti = betti.transform(X_train_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_betti.shape)\n",
    "plot_curve(X_train_betti[1, 0], betti.samplings_[np.inf].reshape(-1,), n_curves=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverting the boolean images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = Inverter(n_jobs=4)\n",
    "inverter.fit(X_train_binarized[:20])\n",
    "X_train_inverted = inverter.transform(X_train_binarized[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train_inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a boolean image filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 28\n",
    "\n",
    "signed_distance_filtration = DilationFiltration(n_iterations=n_iterations, n_jobs=4)\n",
    "signed_distance_filtration.fit(X_train_binarized[:20])\n",
    "X_train_filtered = signed_distance_filtration.transform(X_train_binarized[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting persistence diagrams out of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubical_complex = CubicalPersistence(n_jobs=1)\n",
    "cubical_complex.fit(X_train_filtered)\n",
    "X_train_cubical = cubical_complex.transform(X_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagrams(X_train_cubical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling the diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {'metric': 'bottleneck', 'metric_params': {}}\n",
    "\n",
    "diagram_scaler = Scaler(**metric)\n",
    "diagram_scaler.fit(X_train_cubical)\n",
    "X_train_scaled = diagram_scaler.transform(X_train_cubical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagrams(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the distance matrix between the diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_distance = PairwiseDistance(metric='wasserstein', metric_params={'p': 2, 'delta': 0.1}, n_jobs=1)\n",
    "diagram_distance.fit(X_train_cubical)\n",
    "X_train_distance = diagram_distance.transform(X_train_cubical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(X_train_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('binarizer', Binarizer(threshold=0.4)),\n",
    "    ('filtration', SignedDistanceFiltration(n_iterations=28)),\n",
    "    ('persistence', CubicalPersistence(n_jobs=1)),\n",
    "    ('distance', PairwiseDistance(metric='wasserstein', metric_params={'p': 2, 'delta': 0.1}, n_jobs=1))\n",
    "    ]\n",
    "\n",
    "pipeline_signed_distance = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_signed_distance.fit(X_train[:20])\n",
    "X_train_pipeline_distance = pipeline_signed_distance.fit_transform(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(X_train_pipeline_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying several pipelines based on different filtrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_list = [ np.array([0, 1]), np.array([0, -1]), np.array([1, 0]), np.array([-1, 0]) ]\n",
    "\n",
    "filtration_list = [HeightFiltration(direction=direction) \n",
    "                    for direction in direction_list]\n",
    "\n",
    "steps_list = [ [\n",
    "    ('binarizer', Binarizer(threshold=0.4)),\n",
    "    ('filtration', filtration),\n",
    "    ('persistence', CubicalPersistence()),\n",
    "    ('distance', Amplitude(metric='heat', metric_params={'p': 2}))]\n",
    "    for filtration in filtration_list ]\n",
    "\n",
    "pipeline_list = [ (str(direction_list[i]), Pipeline(steps_list[i])) for i in range(len(steps_list))]\n",
    "feature_union_filtrations = FeatureUnion(pipeline_list, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_union_filtrations.fit(X_train[:20])\n",
    "X_train_filtrations = feature_union_filtrations.transform(X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_curve(X_train_filtrations, n_curves=len(filtration_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
